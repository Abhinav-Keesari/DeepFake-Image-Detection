{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi1OCnl36JCD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVxld7ui8Qss"
      },
      "outputs": [],
      "source": [
        "# Define the paths to the train folder containing real and fake subfolders\n",
        "train_real_path = \"/content/drive/MyDrive/Validation/Real\"\n",
        "train_fake_path = \"/content/drive/MyDrive/Validation/Fake\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAB54eH78cxl"
      },
      "outputs": [],
      "source": [
        "# Define the number of real and fake images you want to use for training\n",
        "num_real_images = 19000\n",
        "num_fake_images = 19000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNQWRYb-8g2t"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder_path, num_images):\n",
        "    images = []\n",
        "    count = 0\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if count >= num_images:\n",
        "            break\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (64, 64))  # Resizing images to fit LeNet architecture\n",
        "        images.append(img)\n",
        "        count += 1\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-JkpDpG8jUd"
      },
      "outputs": [],
      "source": [
        "# Load real and fake images\n",
        "real_images = load_images_from_folder(train_real_path, num_real_images)\n",
        "fake_images = load_images_from_folder(train_fake_path, num_fake_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeerCVLZ-lW8"
      },
      "outputs": [],
      "source": [
        "# Create labels for real and fake images\n",
        "real_labels = np.ones((num_real_images,))\n",
        "fake_labels = np.zeros((num_fake_images,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_TUpK0C-uRk"
      },
      "outputs": [],
      "source": [
        "# Concatenate real and fake images and labels\n",
        "X_train = np.concatenate((real_images, fake_images), axis=0)\n",
        "y_train = np.concatenate((real_labels, fake_labels), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1Y8R0Vo--vD"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data\n",
        "shuffle_indices = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(shuffle_indices)\n",
        "X_train = X_train[shuffle_indices]\n",
        "y_train = y_train[shuffle_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y749r8H_CKz"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values to range [0, 1]\n",
        "X_train = X_train / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNciEprR_CGD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Define the L2 regularization parameter\n",
        "l2_reg = 0.001  # You can adjust this parameter\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(6, kernel_size=(5, 5), input_shape=(64, 64, 3),\n",
        "           kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, kernel_size=(5, 5),\n",
        "           kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    AveragePooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(120, kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(84, kernel_regularizer=regularizers.l2(l2_reg)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0lqA_Wt_KDz"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMPx4V6g_OLb"
      },
      "outputs": [],
      "source": [
        "# Define model checkpoints\n",
        "checkpoint_path = \"lenet_deepfake_detection.h5\"\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='max', restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "seBoUNoyWEIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldQhQ28p_wRU",
        "outputId": "cc49fa52-008d-4821-8ed5-48c8d33caefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.7429\n",
            "Epoch 1: val_accuracy improved from -inf to 0.77658, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 96s 100ms/step - loss: 0.5897 - accuracy: 0.7429 - val_loss: 0.5158 - val_accuracy: 0.7766\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "950/950 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.7907\n",
            "Epoch 2: val_accuracy improved from 0.77658 to 0.79605, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 92s 97ms/step - loss: 0.4954 - accuracy: 0.7907 - val_loss: 0.4853 - val_accuracy: 0.7961\n",
            "Epoch 3/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8115\n",
            "Epoch 3: val_accuracy did not improve from 0.79605\n",
            "950/950 [==============================] - 97s 102ms/step - loss: 0.4587 - accuracy: 0.8115 - val_loss: 0.4889 - val_accuracy: 0.7905\n",
            "Epoch 4/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.8255\n",
            "Epoch 4: val_accuracy improved from 0.79605 to 0.82803, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 94s 99ms/step - loss: 0.4353 - accuracy: 0.8255 - val_loss: 0.4300 - val_accuracy: 0.8280\n",
            "Epoch 5/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.8415\n",
            "Epoch 5: val_accuracy improved from 0.82803 to 0.83329, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 104s 109ms/step - loss: 0.4132 - accuracy: 0.8415 - val_loss: 0.4230 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8513\n",
            "Epoch 6: val_accuracy improved from 0.83329 to 0.83513, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 95s 100ms/step - loss: 0.3980 - accuracy: 0.8513 - val_loss: 0.4277 - val_accuracy: 0.8351\n",
            "Epoch 7/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8586\n",
            "Epoch 7: val_accuracy improved from 0.83513 to 0.83724, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 100s 105ms/step - loss: 0.3891 - accuracy: 0.8586 - val_loss: 0.4169 - val_accuracy: 0.8372\n",
            "Epoch 8/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3745 - accuracy: 0.8671\n",
            "Epoch 8: val_accuracy improved from 0.83724 to 0.85132, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.3745 - accuracy: 0.8671 - val_loss: 0.4109 - val_accuracy: 0.8513\n",
            "Epoch 9/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8744\n",
            "Epoch 9: val_accuracy did not improve from 0.85132\n",
            "950/950 [==============================] - 98s 104ms/step - loss: 0.3656 - accuracy: 0.8744 - val_loss: 0.4194 - val_accuracy: 0.8411\n",
            "Epoch 10/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3635 - accuracy: 0.8790\n",
            "Epoch 10: val_accuracy did not improve from 0.85132\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.3635 - accuracy: 0.8790 - val_loss: 0.4259 - val_accuracy: 0.8446\n",
            "Epoch 11/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8854\n",
            "Epoch 11: val_accuracy did not improve from 0.85132\n",
            "950/950 [==============================] - 94s 99ms/step - loss: 0.3490 - accuracy: 0.8854 - val_loss: 0.4305 - val_accuracy: 0.8463\n",
            "Epoch 12/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8918\n",
            "Epoch 12: val_accuracy improved from 0.85132 to 0.85263, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.3447 - accuracy: 0.8918 - val_loss: 0.4257 - val_accuracy: 0.8526\n",
            "Epoch 13/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.8920\n",
            "Epoch 13: val_accuracy did not improve from 0.85263\n",
            "950/950 [==============================] - 98s 103ms/step - loss: 0.3378 - accuracy: 0.8920 - val_loss: 0.4643 - val_accuracy: 0.8445\n",
            "Epoch 14/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8999\n",
            "Epoch 14: val_accuracy did not improve from 0.85263\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.3367 - accuracy: 0.8999 - val_loss: 0.4499 - val_accuracy: 0.8503\n",
            "Epoch 15/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.9016\n",
            "Epoch 15: val_accuracy improved from 0.85263 to 0.85737, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 95s 100ms/step - loss: 0.3339 - accuracy: 0.9016 - val_loss: 0.4446 - val_accuracy: 0.8574\n",
            "Epoch 16/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.9085\n",
            "Epoch 16: val_accuracy improved from 0.85737 to 0.85921, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 97s 102ms/step - loss: 0.3191 - accuracy: 0.9085 - val_loss: 0.4549 - val_accuracy: 0.8592\n",
            "Epoch 17/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.9100\n",
            "Epoch 17: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.3158 - accuracy: 0.9100 - val_loss: 0.4553 - val_accuracy: 0.8547\n",
            "Epoch 18/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.9129\n",
            "Epoch 18: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.3115 - accuracy: 0.9129 - val_loss: 0.4379 - val_accuracy: 0.8571\n",
            "Epoch 19/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.9171\n",
            "Epoch 19: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.3016 - accuracy: 0.9171 - val_loss: 0.4728 - val_accuracy: 0.8529\n",
            "Epoch 20/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.9172\n",
            "Epoch 20: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.3166 - accuracy: 0.9172 - val_loss: 0.4461 - val_accuracy: 0.8532\n",
            "Epoch 21/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.9207\n",
            "Epoch 21: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.3070 - accuracy: 0.9207 - val_loss: 0.4784 - val_accuracy: 0.8522\n",
            "Epoch 22/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.9215\n",
            "Epoch 22: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.3033 - accuracy: 0.9215 - val_loss: 0.4929 - val_accuracy: 0.8588\n",
            "Epoch 23/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.9243\n",
            "Epoch 23: val_accuracy did not improve from 0.85921\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.2959 - accuracy: 0.9243 - val_loss: 0.4808 - val_accuracy: 0.8533\n",
            "Epoch 24/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.9248\n",
            "Epoch 24: val_accuracy improved from 0.85921 to 0.86342, saving model to lenet_deepfake_detection.h5\n",
            "950/950 [==============================] - 94s 99ms/step - loss: 0.3029 - accuracy: 0.9248 - val_loss: 0.4832 - val_accuracy: 0.8634\n",
            "Epoch 25/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.9284\n",
            "Epoch 25: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.2877 - accuracy: 0.9284 - val_loss: 0.5047 - val_accuracy: 0.8587\n",
            "Epoch 26/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.9277\n",
            "Epoch 26: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 95s 100ms/step - loss: 0.3007 - accuracy: 0.9277 - val_loss: 0.5015 - val_accuracy: 0.8597\n",
            "Epoch 27/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.9310\n",
            "Epoch 27: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.2957 - accuracy: 0.9310 - val_loss: 0.4949 - val_accuracy: 0.8553\n",
            "Epoch 28/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.9334\n",
            "Epoch 28: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 94s 99ms/step - loss: 0.2825 - accuracy: 0.9334 - val_loss: 0.4696 - val_accuracy: 0.8593\n",
            "Epoch 29/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.9300\n",
            "Epoch 29: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 92s 96ms/step - loss: 0.2963 - accuracy: 0.9300 - val_loss: 0.5092 - val_accuracy: 0.8589\n",
            "Epoch 30/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9356\n",
            "Epoch 30: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 97s 103ms/step - loss: 0.2867 - accuracy: 0.9356 - val_loss: 0.5177 - val_accuracy: 0.8589\n",
            "Epoch 31/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.9351\n",
            "Epoch 31: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 91s 96ms/step - loss: 0.2876 - accuracy: 0.9351 - val_loss: 0.5017 - val_accuracy: 0.8588\n",
            "Epoch 32/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.9362\n",
            "Epoch 32: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 93s 98ms/step - loss: 0.2891 - accuracy: 0.9362 - val_loss: 0.5297 - val_accuracy: 0.8516\n",
            "Epoch 33/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.9390\n",
            "Epoch 33: val_accuracy did not improve from 0.86342\n",
            "950/950 [==============================] - 97s 102ms/step - loss: 0.2776 - accuracy: 0.9390 - val_loss: 0.5229 - val_accuracy: 0.8574\n",
            "Epoch 34/100\n",
            "950/950 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.9368\n",
            "Epoch 34: val_accuracy did not improve from 0.86342\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "950/950 [==============================] - 97s 102ms/step - loss: 0.2884 - accuracy: 0.9368 - val_loss: 0.5124 - val_accuracy: 0.8591\n",
            "Epoch 34: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Train the model with early stopping\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=100,  # You can increase the number of epochs\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dw57HXyAQCc"
      },
      "outputs": [],
      "source": [
        "test_real_path = \"/content/drive/MyDrive/Test/Real\"\n",
        "test_fake_path = \"/content/drive/MyDrive/Test/Fake\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTIEcVsbBlRD"
      },
      "outputs": [],
      "source": [
        "# Define the number of real and fake images you want to use for testing\n",
        "num_test_real_images = 1000\n",
        "num_test_fake_images = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE5DMQcrBzWj"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess test images\n",
        "def load_test_images_from_folder(folder_path, num_images):\n",
        "    images = []\n",
        "    count = 0\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if count >= num_images:\n",
        "            break\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (64, 64))  # Resizing images to fit LeNet architecture\n",
        "        images.append(img)\n",
        "        count += 1\n",
        "    return np.array(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8pnHgYkB2Dr"
      },
      "outputs": [],
      "source": [
        "# Load test real and fake images\n",
        "test_real_images = load_test_images_from_folder(test_real_path, num_test_real_images)\n",
        "test_fake_images = load_test_images_from_folder(test_fake_path, num_test_fake_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8Eme_NMB10b"
      },
      "outputs": [],
      "source": [
        "# Create labels for test real and fake images\n",
        "test_real_labels = np.ones((num_test_real_images,))\n",
        "test_fake_labels = np.zeros((num_test_fake_images,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv8IiiyCB7rT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Concatenate test real and fake images and labels\n",
        "X_test = np.concatenate((test_real_images, test_fake_images), axis=0)\n",
        "y_test = np.concatenate((test_real_labels, test_fake_labels), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVMh5YzIDSNb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Shuffle the test data\n",
        "shuffle_indices_test = np.arange(X_test.shape[0])\n",
        "np.random.shuffle(shuffle_indices_test)\n",
        "X_test = X_test[shuffle_indices_test]\n",
        "y_test = y_test[shuffle_indices_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPNKxC2IDVvz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFBKFj1oDYdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2c4f5f-a5a9-4767-a8e3-913365f29e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3233 - accuracy: 0.9155\n",
            "Test Loss: 0.32334011793136597\n",
            "Test Accuracy: 0.9154999852180481\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train[:600], y_train[:600], verbose=1)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijBH45QjPKsC",
        "outputId": "c4560897-f476-431c-8237-ad53b027f367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 31ms/step - loss: 0.2682 - accuracy: 0.9417\n",
            "Test Loss: 0.2682012617588043\n",
            "Test Accuracy: 0.9416666626930237\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}